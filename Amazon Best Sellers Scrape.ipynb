{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import system\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapes the best seller URLs from Amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_sellers_url():\n",
    "    #webdriver to amazon best seller page \n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    pd.set_option('display.max_colwidth', 200)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.amazon.com/Best-Sellers/zgbs')\n",
    "    \n",
    "    best_sellers_total = []\n",
    "    for i in range(40):\n",
    "        x_path = driver.find_element_by_xpath(f'//*[@id=\"zg_browseRoot\"]/ul/li[{i+1}]/a')\n",
    "        url = x_path.get_attribute('href')\n",
    "        best_sellers_total.append(url)\n",
    "        \n",
    "    driver.quit()\n",
    "        \n",
    "    return best_sellers_total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_urls = best_sellers_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Seller Item Scrape \n",
    "- Takes in the URL's from the above function \n",
    "- Scrapes the products from the amazon best seller lists \n",
    "- Scrapes URL's for each individual product to later feed into camelcamelcamel for price history\n",
    "- creates list of ASIN numbers which will be used as the primary IDs in the DB \n",
    "- scrapes the ratings \n",
    "- names of the items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_sellers_scrape(url):\n",
    "    #webdriver to amazon best seller page \n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    pd.set_option('display.max_colwidth', 200)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #final Url list: outputs urls that will go to camelcamelcamel\n",
    "    final_urls = []\n",
    "    #will create list for primary keys \n",
    "    id_list = []\n",
    "    #scrapes the name, ratings, reviews and price\n",
    "    ratings = []\n",
    "    item = driver.find_element_by_xpath('//*[@id=\"zg-center-div\"]')\n",
    "    items = item.text.split('#')\n",
    "    final_list = []\n",
    "#     [re.findall(r'\\n(.*)',i)[:3] for i in items if re.findall(r'\\n(.*)',i) != None and len(re.findall(r'\\n(.*)',i))!= 0]\n",
    "    for i in items:\n",
    "        try:\n",
    "            string_text = re.findall(r'\\n(.*)',i)\n",
    "            if re.findall(r'\\n(.*)',i) != None and len(re.findall(r'\\n(.*)',i))!= 0 :\n",
    "                final_list.append(string_text[:3])\n",
    "            for z in final_list:\n",
    "                if z[2] == '':\n",
    "                    z[2] = string_text[1]\n",
    "                    z[1] = '000'\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    link_list = [i.get_attribute('href') for i in driver.find_elements_by_class_name('a-link-normal')]\n",
    "    \n",
    "    for i in range(1,51):\n",
    "        try:\n",
    "            if driver.find_element_by_xpath(f'//*[@id=\"zg-ordered-list\"]/li[{i}]/span/div/span/div[1]/a[1]'):\n",
    "                rating = driver.find_element_by_xpath(f'//*[@id=\"zg-ordered-list\"]/li[{i}]/span/div/span/div[1]/a[1]')\n",
    "                ratings.append(rating.get_attribute('title'))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "    #trys going to the second page if there is one.  If there are no best sellers it moves to the next page\n",
    "    try:\n",
    "        page_2 = driver.find_element_by_xpath('//*[@id=\"zg-center-div\"]/div[2]/div/ul/li[3]/a')\n",
    "    except:\n",
    "        pass \n",
    "    try:\n",
    "        page_2 = driver.find_element_by_class_name('a-normal')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        page_2.click()\n",
    "    except:\n",
    "        pass\n",
    "   \n",
    "    \n",
    "    time.sleep(1.5)\n",
    "    #scrapes the name, ratings, reviews and price for the second page \n",
    "    item = driver.find_element_by_xpath('//*[@id=\"zg-center-div\"]')\n",
    "    items = item.text.split('#')\n",
    "    final_list1 = []\n",
    "    \n",
    "    for i in items:\n",
    "        try:\n",
    "            string_text = re.findall(r'\\n(.*)',i)\n",
    "            if re.findall(r'\\n(.*)',i) != None and len(re.findall(r'\\n(.*)',i))!= 0 :\n",
    "                final_list1.append(string_text[:3])\n",
    "            for z in final_list1:\n",
    "                if z[2] == '':\n",
    "                    z[2] = string_text[1]\n",
    "                    z[1] = '000'\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    link_list1 = [i.get_attribute('href') for i in driver.find_elements_by_class_name('a-link-normal')]\n",
    "    #cleans up the links and appends them to a final url list \n",
    "    for i in link_list + link_list1:\n",
    "        a = str(i)\n",
    "        if a.find('reviews') == -1 and a not in final_urls and a.find('gp') == -1 and len(a) != 0:\n",
    "            final_urls.append(a)\n",
    "            \n",
    "    #gets ids from urls and puts them in list id_list\n",
    "    for z in final_urls:\n",
    "        for i in range(len(z)-1):\n",
    "            if z[i:i+4] == '/dp/':\n",
    "                id_list.append(z[i+4:i+14])\n",
    "                \n",
    "    for i in range(1,51):\n",
    "        try:\n",
    "            rating = driver.find_element_by_xpath(f'//*[@id=\"zg-ordered-list\"]/li[{i}]/span/div/span/div[1]/a[1]')\n",
    "            ratings.append(rating.get_attribute('title'))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    driver.quit()\n",
    "    return final_list + final_list1, final_urls, id_list, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "info, urls, ids, ratings = best_sellers_scrape(best_urls[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_all():\n",
    "#     info_all = []\n",
    "#     urls_all = []\n",
    "#     ids_all = []\n",
    "#     ratings_all = []\n",
    "#     for i in range(len(best_urls)):\n",
    "#         try:\n",
    "#             info, urls, ids, ratings = best_sellers_scrape(best_urls[i])\n",
    "#             info_all.append(info)\n",
    "#             urls_all.append(urls)\n",
    "#             ids_all.append(ids)\n",
    "#             ratings_all.append(ratings)\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_lists(info, urls, ids, ratings):\n",
    "    new_list = []\n",
    "    final_list = []\n",
    "    for i in range(len(info)):\n",
    "        new_list.append(info[i][0])\n",
    "        new_list.append(info[i][1])\n",
    "        new_list.append(info[i][2])\n",
    "        new_list.append(ids[i])\n",
    "        new_list.append(ratings[i][:3])\n",
    "        new_list.append(urls[i])\n",
    "        final_list.append(new_list)\n",
    "        new_list = []\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_zip():\n",
    "    listy = []\n",
    "    for i in range(len(best_urls)):\n",
    "        try:\n",
    "            info, urls, ids, ratings = best_sellers_scrape(best_urls[i])\n",
    "            listy.append(zip_lists(info, urls, ids, ratings))\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return listy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_item_data = scrape_all_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_for_camel(amazon_item_data):\n",
    "    urls = []\n",
    "    for category in amazon_item_data:\n",
    "        for item in category:\n",
    "            urls.append(item[-1])\n",
    "            \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_urls = get_urls_for_camel(amazon_item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
